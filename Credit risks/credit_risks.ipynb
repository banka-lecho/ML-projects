{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f80485",
   "metadata": {},
   "source": [
    "## Credit risk Analysis\n",
    "\n",
    "I have divided the credit risk study into several independent parts: data preparation, training on logistic and linear regression and training on gradient boosting algorithms.\n",
    "\n",
    "**№ 1** - Data preparation\n",
    "\n",
    "**№ 2** - Forecasting the risk of customer default using logistic regression and linear regression\n",
    "\n",
    "**№ 3** - Forecasting the risk of client default using XGBoost, LightGBM and CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f039d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style()\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, cross_val_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1b24703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default matplotlib parameters\n",
    "COLOR = '#ababab'\n",
    "mpl.rcParams['figure.titlesize'] = 16\n",
    "mpl.rcParams['text.color'] = 'black'\n",
    "mpl.rcParams['axes.labelcolor'] = COLOR\n",
    "mpl.rcParams['xtick.color'] = COLOR\n",
    "mpl.rcParams['ytick.color'] = COLOR\n",
    "mpl.rcParams['grid.color'] = COLOR\n",
    "mpl.rcParams['grid.alpha'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccd9dae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows and colums:  (45000, 43)\n"
     ]
    }
   ],
   "source": [
    "global_data = pd.read_csv('./risk/acquisition_train.csv')\n",
    "print('rows and colums: ', global_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706171b8",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74135159",
   "metadata": {},
   "source": [
    "'Target default' - is our target, that we want to predict \n",
    "\n",
    "Obviously, that data have a null values or values that is not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a569981b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids                                                  0.000000\n",
      "email                                                0.000000\n",
      "external_data_provider_credit_checks_last_month      0.000000\n",
      "external_data_provider_first_name                    0.000000\n",
      "external_data_provider_fraud_score                   0.000000\n",
      "profile_phone_number                                 0.000000\n",
      "application_time_applied                             0.000000\n",
      "reported_income                                      0.000000\n",
      "shipping_state                                       0.000000\n",
      "application_time_in_funnel                           0.000000\n",
      "score_6                                              0.000000\n",
      "profile_tags                                         0.000000\n",
      "score_5                                              0.000000\n",
      "score_4                                              0.000000\n",
      "shipping_zip_code                                    0.000000\n",
      "risk_rate                                            1.248889\n",
      "n_accounts                                           1.248889\n",
      "score_1                                              1.248889\n",
      "score_2                                              1.248889\n",
      "score_3                                              1.248889\n",
      "channel                                              1.248889\n",
      "zip                                                  1.248889\n",
      "state                                                1.248889\n",
      "real_state                                           1.248889\n",
      "income                                               1.248889\n",
      "reason                                               1.257778\n",
      "n_defaulted_loans                                    1.275556\n",
      "n_bankruptcies                                       1.548889\n",
      "user_agent                                           1.604444\n",
      "lat_lon                                              3.028889\n",
      "external_data_provider_email_seen_before             4.962222\n",
      "target_default                                       7.242222\n",
      "job_name                                             7.413333\n",
      "marketing_channel                                    7.951111\n",
      "facebook_profile                                     9.906667\n",
      "n_issues                                            25.653333\n",
      "credit_limit                                        30.666667\n",
      "external_data_provider_credit_checks_last_year      33.608889\n",
      "external_data_provider_credit_checks_last_2_year    50.284444\n",
      "ok_since                                            58.988889\n",
      "last_borrowed_in_months                             66.568889\n",
      "last_amount_borrowed                                66.568889\n",
      "target_fraud                                        96.617778\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(((global_data.isnull().sum() / global_data.shape[0]) * 100).sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7cee1d",
   "metadata": {},
   "source": [
    "Some signs have a large number of missing values, so let's delete them if there are more than 25 missing values%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16940710",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['email', 'reason', 'zip', 'job_name', 'external_data_provider_first_name', 'lat_lon',\n",
    "                       'shipping_zip_code', 'user_agent', 'profile_tags', 'marketing_channel',\n",
    "                       'profile_phone_number', 'application_time_applied', 'ids']\n",
    "data = global_data\n",
    "data.dropna(subset=['target_default'], inplace=True)\n",
    "data.drop(columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42b47dc",
   "metadata": {},
   "source": [
    "Drop large values like 'inf' or '-999'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44ed30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \"inf\" values with \"nan\"\n",
    "data['reported_income'] = data['reported_income'].replace(np.inf, np.nan)\n",
    "\n",
    "# replace \"-999\" values with \"nan\"\n",
    "data.loc[data['external_data_provider_email_seen_before'] == -999, 'external_data_provider_email_seen_before'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f1d05",
   "metadata": {},
   "source": [
    "Now fill in the missing values in the remaining signs. To do this, use the SimpleImputer library to fill in and standart libraries for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a2e988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# отбираем только количественные\n",
    "num_features = data.select_dtypes(exclude=['object']).columns\n",
    "# категориальные\n",
    "categorical_features = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# заполните пропущенные значения для \"last_amount_borrowed\", \"last_borrowed_in_months\" и \"n_issues\".\n",
    "data['last_amount_borrowed'].fillna(value=0, inplace=True)\n",
    "data['last_borrowed_in_months'].fillna(value=0, inplace=True)\n",
    "data['n_issues'].fillna(value=0, inplace=True)\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "data.loc[:, num_features] = imputer.fit_transform(data.loc[:, num_features])\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "data.loc[:, categorical_features] = imputer.fit_transform(data.loc[:, categorical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f53b5ae",
   "metadata": {},
   "source": [
    "Now we need to provide encoding categorical features and scaling of num features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6145e3ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        1\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "44995    0\n",
       "44996    0\n",
       "44997    0\n",
       "44998    1\n",
       "44999    0\n",
       "Name: target_default, Length: 41741, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_var = data.nunique()[data.nunique() == 2].keys().tolist()\n",
    "cat_var = [col for col in data.select_dtypes(['object']).columns.tolist() if col not in bin_var]\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "norm_data = data.copy()\n",
    "for i in bin_var:\n",
    "    norm_data[i] = encoder.fit_transform(norm_data[i])\n",
    "    \n",
    "norm_data = pd.get_dummies(norm_data, columns=cat_var)\n",
    "norm_data['target_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b66d3b17",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m df_num:\n\u001b[0;32m---> 11\u001b[0m     sns\u001b[38;5;241m.\u001b[39mhistplot(df_num[i], bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, ax\u001b[38;5;241m=\u001b[39m\u001b[43max\u001b[49m\u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[43m]\u001b[49m[c])\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;241m==\u001b[39m ncols \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     13\u001b[0m         r \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2500x1600 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_num = norm_data[num_features]\n",
    "nrows = 3\n",
    "ncols = 4\n",
    "\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(25, 16))\n",
    "\n",
    "r = 0\n",
    "c = 0\n",
    "\n",
    "for i in df_num:\n",
    "    sns.histplot(df_num[i], bins=15, kde=False, ax=ax[r][c])\n",
    "    if c == ncols - 1:\n",
    "        r += 1\n",
    "        c = 0\n",
    "    else:\n",
    "        c += 1\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41145f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data.drop('external_data_provider_credit_checks_last_2_year', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404ee010",
   "metadata": {},
   "source": [
    "## Now we can make the X and y as data and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41e98416",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = norm_data.copy()\n",
    "y = X['target_default']\n",
    "X.drop('target_default', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3aca57",
   "metadata": {},
   "source": [
    "## Model: LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc5ae797",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "/Users/anastasiaspileva/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "/Users/anastasiaspileva/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "/Users/anastasiaspileva/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "/Users/anastasiaspileva/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "/Users/anastasiaspileva/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      " N =          146     M =           10\n",
      "\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "           * * *\n",
      "\n",
      "\n",
      "           * * *\n",
      "Tit   = total number of iterations\n",
      "\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "At X0         0 variables are exactly at the bounds\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "\n",
      "Tnf   = total number of function evaluations\n",
      "           * * *\n",
      "\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "Skip  = number of BFGS updates skipped\n",
      "F     = final function value\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.271D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.27110D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.303D+17   2.315D+04\n",
      "  F =   23145.570653257691     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31456D+04    |proj g|=  1.30288D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.208D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.20755D+17\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  146      1     21      1     0     0   1.144D+17   2.315D+04\n",
      "  F =   23146.263800438253     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          146     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.31463D+04    |proj g|=  1.14399D+17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m c_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m      8\u001b[0m logit_searcher \u001b[38;5;241m=\u001b[39m LogisticRegressionCV(Cs\u001b[38;5;241m=\u001b[39mc_values, cv\u001b[38;5;241m=\u001b[39mskf, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mlogit_searcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_logistic.py:1878\u001b[0m, in \u001b[0;36mLogisticRegressionCV.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1875\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1876\u001b[0m     prefer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocesses\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintercept_scaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1900\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_encoded_labels\u001b[49m\n\u001b[1;32m   1903\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ml1_ratios_\u001b[49m\n\u001b[1;32m   1905\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[38;5;66;03m# _log_reg_scoring_path will output different shapes depending on the\u001b[39;00m\n\u001b[1;32m   1908\u001b[0m \u001b[38;5;66;03m# multi_class param, so we need to reshape the outputs accordingly.\u001b[39;00m\n\u001b[1;32m   1909\u001b[0m \u001b[38;5;66;03m# Cs is of shape (n_classes . n_folds . n_l1_ratios, n_Cs) and all the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;66;03m#  (n_classes, n_folds, n_Cs . n_l1_ratios) or\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;66;03m#  (1, n_folds, n_Cs . n_l1_ratios)\u001b[39;00m\n\u001b[1;32m   1918\u001b[0m coefs_paths, Cs, scores, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/joblib/parallel.py:1944\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1940\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1944\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/joblib/parallel.py:1587\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1586\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1587\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1698\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1699\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1700\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# поскольку у нас не особо маленький датасет, то лучше использовать solver 'liblinear'\n",
    "# можно еще использовать newton-cholesky, так как у нас объектов намного больше чем признаков \n",
    "# а вообще можно перебрать все методы в CV \n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "c_values = np.logspace(-2, 3, 500)\n",
    "\n",
    "logit_searcher = LogisticRegressionCV(Cs=c_values, cv=skf, verbose=1, n_jobs=-1)\n",
    "logit_searcher.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "696f036c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegressionCV' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mlogit_searcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m logit_searcher\u001b[38;5;241m.\u001b[39mscore(X, y)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/linear_model/_base.py:433\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m    432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegressionCV' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "y_pred = logit_searcher.predict(X)\n",
    "logit_searcher.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = X.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b140e4ec",
   "metadata": {},
   "source": [
    "Here I checked that there is no imbalance of classes. It turned out that there is. If the classes are unbalanced, the logistic regression will be biased towards the smaller class, so we have very poor results. 84% is one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum0 = [i for i in y if i == 0]\n",
    "print(len(sum0))\n",
    "\n",
    "sum1 = [i for i in y if i == 1]\n",
    "print(len(sum1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4047d38",
   "metadata": {},
   "source": [
    "## Model: RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6cb7dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=17, shuffle=True),\n",
       "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                              n_estimators=40, n_jobs=-1,\n",
       "                                              random_state=17),\n",
       "             param_grid={&#x27;max_depth&#x27;: range(5, 15),\n",
       "                         &#x27;max_features&#x27;: [4, 5, 6, 7]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=17, shuffle=True),\n",
       "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                              n_estimators=40, n_jobs=-1,\n",
       "                                              random_state=17),\n",
       "             param_grid={&#x27;max_depth&#x27;: range(5, 15),\n",
       "                         &#x27;max_features&#x27;: [4, 5, 6, 7]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=40, n_jobs=-1,\n",
       "                       random_state=17)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=40, n_jobs=-1,\n",
       "                       random_state=17)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=17, shuffle=True),\n",
       "             estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                              n_estimators=40, n_jobs=-1,\n",
       "                                              random_state=17),\n",
       "             param_grid={'max_depth': range(5, 15),\n",
       "                         'max_features': [4, 5, 6, 7]})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    n_estimators = 40,\n",
    "    random_state = 17,\n",
    "    n_jobs = -1\n",
    "    )\n",
    "max_depth_values = range(5, 15)\n",
    "max_features_values = [4,5,6,7]\n",
    "params = {'max_depth': max_depth_values, 'max_features': max_features_values}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle = True, random_state=17)\n",
    "\n",
    "grid_forest = GridSearchCV(forest, params, cv=skf)\n",
    "grid_forest.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87f0590d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7296184457360076"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_forest.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b894cb7b",
   "metadata": {},
   "source": [
    "### Random Forest with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e738b5d8",
   "metadata": {},
   "source": [
    "**We didn't get the best result. Let's apply the principal component method. To do this, you first need to scale the data, as this is required by the PCA method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f43af486",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=17)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24cb4c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cumulative Variance Ratio</th>\n",
       "      <th>Explained Variance Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018221</td>\n",
       "      <td>0.018221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035905</td>\n",
       "      <td>0.017685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.016894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.068848</td>\n",
       "      <td>0.016049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.083703</td>\n",
       "      <td>0.014854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.970649</td>\n",
       "      <td>0.006237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.976685</td>\n",
       "      <td>0.006036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.982444</td>\n",
       "      <td>0.005759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.987975</td>\n",
       "      <td>0.005531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.992925</td>\n",
       "      <td>0.004950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cumulative Variance Ratio  Explained Variance Ratio\n",
       "0                     0.018221                  0.018221\n",
       "1                     0.035905                  0.017685\n",
       "2                     0.052800                  0.016894\n",
       "3                     0.068848                  0.016049\n",
       "4                     0.083703                  0.014854\n",
       "..                         ...                       ...\n",
       "125                   0.970649                  0.006237\n",
       "126                   0.976685                  0.006036\n",
       "127                   0.982444                  0.005759\n",
       "128                   0.987975                  0.005531\n",
       "129                   0.992925                  0.004950\n",
       "\n",
       "[130 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pca_test = PCA(n_components=140)\n",
    "pca_test.fit(X_train_scaled)\n",
    "sns.set(style='whitegrid')\n",
    "plt.plot(np.cumsum(pca_test.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.axvline(linewidth=4, color='r', linestyle = '--', x=130, ymin=0, ymax=1)\n",
    "display(plt.show())\n",
    "evr = pca_test.explained_variance_ratio_\n",
    "cvr = np.cumsum(pca_test.explained_variance_ratio_)\n",
    "pca_df = pd.DataFrame()\n",
    "pca_df['Cumulative Variance Ratio'] = cvr\n",
    "pca_df['Explained Variance Ratio'] = evr\n",
    "display(pca_df.head(130))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c96ff3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA Component 0</th>\n",
       "      <th>PCA Component 1</th>\n",
       "      <th>PCA Component 2</th>\n",
       "      <th>PCA Component 3</th>\n",
       "      <th>PCA Component 4</th>\n",
       "      <th>PCA Component 5</th>\n",
       "      <th>PCA Component 6</th>\n",
       "      <th>PCA Component 7</th>\n",
       "      <th>PCA Component 8</th>\n",
       "      <th>PCA Component 9</th>\n",
       "      <th>...</th>\n",
       "      <th>PCA Component 110</th>\n",
       "      <th>PCA Component 111</th>\n",
       "      <th>PCA Component 112</th>\n",
       "      <th>PCA Component 113</th>\n",
       "      <th>PCA Component 114</th>\n",
       "      <th>PCA Component 115</th>\n",
       "      <th>PCA Component 116</th>\n",
       "      <th>PCA Component 117</th>\n",
       "      <th>PCA Component 118</th>\n",
       "      <th>PCA Component 119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.064601</td>\n",
       "      <td>0.095412</td>\n",
       "      <td>0.149581</td>\n",
       "      <td>-0.034918</td>\n",
       "      <td>-0.064557</td>\n",
       "      <td>-0.033598</td>\n",
       "      <td>-0.057240</td>\n",
       "      <td>-0.086981</td>\n",
       "      <td>0.194067</td>\n",
       "      <td>-0.328372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101735</td>\n",
       "      <td>0.051848</td>\n",
       "      <td>0.054447</td>\n",
       "      <td>0.008076</td>\n",
       "      <td>-0.058951</td>\n",
       "      <td>-0.021471</td>\n",
       "      <td>-0.001446</td>\n",
       "      <td>-0.061785</td>\n",
       "      <td>-0.065624</td>\n",
       "      <td>-0.053105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.010305</td>\n",
       "      <td>-0.008461</td>\n",
       "      <td>-0.012634</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>-0.003472</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>-0.007350</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>0.017708</td>\n",
       "      <td>0.033802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008553</td>\n",
       "      <td>-0.096167</td>\n",
       "      <td>0.134544</td>\n",
       "      <td>0.050775</td>\n",
       "      <td>-0.259550</td>\n",
       "      <td>0.169580</td>\n",
       "      <td>-0.031188</td>\n",
       "      <td>0.189137</td>\n",
       "      <td>-0.187965</td>\n",
       "      <td>-0.125612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003023</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>-0.006859</td>\n",
       "      <td>-0.007896</td>\n",
       "      <td>-0.005239</td>\n",
       "      <td>-0.000570</td>\n",
       "      <td>0.016402</td>\n",
       "      <td>-0.016376</td>\n",
       "      <td>0.015354</td>\n",
       "      <td>-0.015398</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115601</td>\n",
       "      <td>-0.147321</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>-0.275762</td>\n",
       "      <td>-0.066555</td>\n",
       "      <td>0.102846</td>\n",
       "      <td>-0.036668</td>\n",
       "      <td>0.026355</td>\n",
       "      <td>0.187172</td>\n",
       "      <td>-0.112632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.013998</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>-0.000796</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.053110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009195</td>\n",
       "      <td>0.028672</td>\n",
       "      <td>-0.065062</td>\n",
       "      <td>-0.167461</td>\n",
       "      <td>-0.121776</td>\n",
       "      <td>-0.198561</td>\n",
       "      <td>-0.269146</td>\n",
       "      <td>0.105277</td>\n",
       "      <td>-0.220381</td>\n",
       "      <td>0.250818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.300387</td>\n",
       "      <td>0.053086</td>\n",
       "      <td>0.155804</td>\n",
       "      <td>0.087241</td>\n",
       "      <td>0.040838</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>0.022628</td>\n",
       "      <td>-0.076419</td>\n",
       "      <td>-0.109275</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006997</td>\n",
       "      <td>0.018786</td>\n",
       "      <td>-0.019126</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.057646</td>\n",
       "      <td>-0.021578</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>-0.009909</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.030523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.009628</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>-0.003954</td>\n",
       "      <td>0.010806</td>\n",
       "      <td>-0.006922</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>-0.006228</td>\n",
       "      <td>0.019092</td>\n",
       "      <td>-0.021810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084221</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>-0.036401</td>\n",
       "      <td>-0.000650</td>\n",
       "      <td>-0.130169</td>\n",
       "      <td>-0.051637</td>\n",
       "      <td>-0.003274</td>\n",
       "      <td>0.064843</td>\n",
       "      <td>0.042591</td>\n",
       "      <td>-0.130395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.007582</td>\n",
       "      <td>-0.003397</td>\n",
       "      <td>-0.008297</td>\n",
       "      <td>-0.005823</td>\n",
       "      <td>0.013446</td>\n",
       "      <td>-0.006934</td>\n",
       "      <td>-0.008615</td>\n",
       "      <td>-0.003172</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.026688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011875</td>\n",
       "      <td>-0.119707</td>\n",
       "      <td>0.047384</td>\n",
       "      <td>0.063971</td>\n",
       "      <td>-0.025991</td>\n",
       "      <td>-0.035614</td>\n",
       "      <td>0.038532</td>\n",
       "      <td>0.074590</td>\n",
       "      <td>-0.050011</td>\n",
       "      <td>0.092143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.009326</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>-0.009827</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-0.005563</td>\n",
       "      <td>0.005960</td>\n",
       "      <td>0.007583</td>\n",
       "      <td>-0.006649</td>\n",
       "      <td>-0.001368</td>\n",
       "      <td>0.006172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047763</td>\n",
       "      <td>0.196030</td>\n",
       "      <td>0.048115</td>\n",
       "      <td>0.185367</td>\n",
       "      <td>0.215839</td>\n",
       "      <td>-0.126637</td>\n",
       "      <td>0.101307</td>\n",
       "      <td>0.133376</td>\n",
       "      <td>-0.057270</td>\n",
       "      <td>0.061880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.010493</td>\n",
       "      <td>0.010122</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.015159</td>\n",
       "      <td>-0.018470</td>\n",
       "      <td>-0.013892</td>\n",
       "      <td>-0.001833</td>\n",
       "      <td>-0.009371</td>\n",
       "      <td>-0.005705</td>\n",
       "      <td>-0.046538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025713</td>\n",
       "      <td>-0.025032</td>\n",
       "      <td>-0.008769</td>\n",
       "      <td>0.022336</td>\n",
       "      <td>-0.009790</td>\n",
       "      <td>0.014878</td>\n",
       "      <td>-0.007446</td>\n",
       "      <td>0.031819</td>\n",
       "      <td>-0.036528</td>\n",
       "      <td>-0.000950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.006665</td>\n",
       "      <td>-0.009116</td>\n",
       "      <td>-0.011321</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.013391</td>\n",
       "      <td>-0.008989</td>\n",
       "      <td>-0.003035</td>\n",
       "      <td>-0.003731</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202643</td>\n",
       "      <td>0.042335</td>\n",
       "      <td>0.101392</td>\n",
       "      <td>-0.026907</td>\n",
       "      <td>-0.009656</td>\n",
       "      <td>0.043394</td>\n",
       "      <td>0.030425</td>\n",
       "      <td>-0.186482</td>\n",
       "      <td>-0.021940</td>\n",
       "      <td>0.052521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PCA Component 0  PCA Component 1  PCA Component 2  PCA Component 3  \\\n",
       "0          -0.064601         0.095412         0.149581        -0.034918   \n",
       "1          -0.010305        -0.008461        -0.012634         0.001522   \n",
       "2           0.003023         0.002989        -0.006859        -0.007896   \n",
       "3           0.006985         0.002841         0.013998         0.001443   \n",
       "4          -0.300387         0.053086         0.155804         0.087241   \n",
       "..               ...              ...              ...              ...   \n",
       "140         0.009628        -0.000252        -0.003954         0.010806   \n",
       "141         0.007582        -0.003397        -0.008297        -0.005823   \n",
       "142         0.009326         0.012189        -0.009827         0.000767   \n",
       "143         0.010493         0.010122         0.005469         0.015159   \n",
       "144         0.006665        -0.009116        -0.011321         0.002189   \n",
       "\n",
       "     PCA Component 4  PCA Component 5  PCA Component 6  PCA Component 7  \\\n",
       "0          -0.064557        -0.033598        -0.057240        -0.086981   \n",
       "1          -0.003472         0.014941        -0.007350         0.013831   \n",
       "2          -0.005239        -0.000570         0.016402        -0.016376   \n",
       "3           0.006732        -0.000796         0.001893         0.002700   \n",
       "4           0.040838         0.023674         0.022628        -0.076419   \n",
       "..               ...              ...              ...              ...   \n",
       "140        -0.006922        -0.001477        -0.000269        -0.006228   \n",
       "141         0.013446        -0.006934        -0.008615        -0.003172   \n",
       "142        -0.005563         0.005960         0.007583        -0.006649   \n",
       "143        -0.018470        -0.013892        -0.001833        -0.009371   \n",
       "144         0.010577         0.013391        -0.008989        -0.003035   \n",
       "\n",
       "     PCA Component 8  PCA Component 9  ...  PCA Component 110  \\\n",
       "0           0.194067        -0.328372  ...           0.101735   \n",
       "1           0.017708         0.033802  ...          -0.008553   \n",
       "2           0.015354        -0.015398  ...          -0.115601   \n",
       "3           0.001083         0.053110  ...           0.009195   \n",
       "4          -0.109275         0.006950  ...          -0.006997   \n",
       "..               ...              ...  ...                ...   \n",
       "140         0.019092        -0.021810  ...           0.084221   \n",
       "141         0.006635         0.026688  ...          -0.011875   \n",
       "142        -0.001368         0.006172  ...          -0.047763   \n",
       "143        -0.005705        -0.046538  ...           0.025713   \n",
       "144        -0.003731         0.010724  ...          -0.202643   \n",
       "\n",
       "     PCA Component 111  PCA Component 112  PCA Component 113  \\\n",
       "0             0.051848           0.054447           0.008076   \n",
       "1            -0.096167           0.134544           0.050775   \n",
       "2            -0.147321           0.004087          -0.275762   \n",
       "3             0.028672          -0.065062          -0.167461   \n",
       "4             0.018786          -0.019126           0.001168   \n",
       "..                 ...                ...                ...   \n",
       "140           0.007222          -0.036401          -0.000650   \n",
       "141          -0.119707           0.047384           0.063971   \n",
       "142           0.196030           0.048115           0.185367   \n",
       "143          -0.025032          -0.008769           0.022336   \n",
       "144           0.042335           0.101392          -0.026907   \n",
       "\n",
       "     PCA Component 114  PCA Component 115  PCA Component 116  \\\n",
       "0            -0.058951          -0.021471          -0.001446   \n",
       "1            -0.259550           0.169580          -0.031188   \n",
       "2            -0.066555           0.102846          -0.036668   \n",
       "3            -0.121776          -0.198561          -0.269146   \n",
       "4             0.057646          -0.021578           0.007700   \n",
       "..                 ...                ...                ...   \n",
       "140          -0.130169          -0.051637          -0.003274   \n",
       "141          -0.025991          -0.035614           0.038532   \n",
       "142           0.215839          -0.126637           0.101307   \n",
       "143          -0.009790           0.014878          -0.007446   \n",
       "144          -0.009656           0.043394           0.030425   \n",
       "\n",
       "     PCA Component 117  PCA Component 118  PCA Component 119  \n",
       "0            -0.061785          -0.065624          -0.053105  \n",
       "1             0.189137          -0.187965          -0.125612  \n",
       "2             0.026355           0.187172          -0.112632  \n",
       "3             0.105277          -0.220381           0.250818  \n",
       "4            -0.009909           0.010616           0.030523  \n",
       "..                 ...                ...                ...  \n",
       "140           0.064843           0.042591          -0.130395  \n",
       "141           0.074590          -0.050011           0.092143  \n",
       "142           0.133376          -0.057270           0.061880  \n",
       "143           0.031819          -0.036528          -0.000950  \n",
       "144          -0.186482          -0.021940           0.052521  \n",
       "\n",
       "[145 rows x 120 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=120)\n",
    "pca.fit(X_train_scaled)\n",
    "X_train_scaled_pca = pca.transform(X_train_scaled)\n",
    "X_test_scaled_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "pca_dims = []\n",
    "for x in range(0, len(pca_df)):\n",
    "    pca_dims.append('PCA Component {}'.format(x))\n",
    "    \n",
    "len(columns)\n",
    "    \n",
    "pca_test_df = pd.DataFrame(pca_test.components_, index=pca_dims)\n",
    "pca_test_df.head(120).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19ee6499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_scaled_pca, y_train)\n",
    "display(rfc.score(X_train_scaled_pca, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c0de810",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 21\u001b[0m\n\u001b[1;32m      8\u001b[0m param_dist \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: n_estimators,\n\u001b[1;32m      9\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m: max_features,\n\u001b[1;32m     10\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: max_depth,\n\u001b[1;32m     11\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m: min_samples_split,\n\u001b[1;32m     12\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: min_samples_leaf,\n\u001b[1;32m     13\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap\u001b[39m\u001b[38;5;124m'\u001b[39m: bootstrap}\n\u001b[1;32m     14\u001b[0m rs \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(rfc, \n\u001b[1;32m     15\u001b[0m                         param_dist, \n\u001b[1;32m     16\u001b[0m                         n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m                         n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m     20\u001b[0m                         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled_pca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m rs\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/model_selection/_search.py:933\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    931\u001b[0m refit_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 933\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/joblib/parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1784\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/tree/_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Мой ноут на 16 ГБ оперативы не тянет: греется как сковородка и выключается\n",
    "\"\"\"\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 100, stop = 300, num = 10)]\n",
    "# max_features = ['log2', 'sqrt']\n",
    "# max_depth = [int(x) for x in np.linspace(start = 1, stop = 15, num = 15)]\n",
    "# min_samples_split = [int(x) for x in n p.linspace(start = 2, stop = 50, num = 10)]\n",
    "# min_samples_leaf = [int(x) for x in np.linspace(start = 2, stop = 50, num = 10)]\n",
    "# bootstrap = [True, False]\n",
    "# param_dist = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "# rs = RandomizedSearchCV(rfc, \n",
    "#                         param_dist, \n",
    "#                         n_iter = 100, \n",
    "#                         cv = 3, \n",
    "#                         verbose = 1, \n",
    "#                         n_jobs=-1, \n",
    "#                         random_state=0)\n",
    "# rs.fit(X_train_scaled_pca, y_train)\n",
    "# rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c600ec",
   "metadata": {},
   "source": [
    "Похожая концепция как с прошлом, но только GridSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b12a6687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=17, shuffle=True),\n",
       "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                              n_estimators=40, n_jobs=-1,\n",
       "                                              random_state=17),\n",
       "             param_grid={&#x27;max_depth&#x27;: range(5, 15),\n",
       "                         &#x27;max_features&#x27;: [4, 5, 6, 7]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=17, shuffle=True),\n",
       "             estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                              n_estimators=40, n_jobs=-1,\n",
       "                                              random_state=17),\n",
       "             param_grid={&#x27;max_depth&#x27;: range(5, 15),\n",
       "                         &#x27;max_features&#x27;: [4, 5, 6, 7]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=40, n_jobs=-1,\n",
       "                       random_state=17)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=40, n_jobs=-1,\n",
       "                       random_state=17)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=17, shuffle=True),\n",
       "             estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                              n_estimators=40, n_jobs=-1,\n",
       "                                              random_state=17),\n",
       "             param_grid={'max_depth': range(5, 15),\n",
       "                         'max_features': [4, 5, 6, 7]})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(\n",
    "    class_weight = 'balanced',\n",
    "    n_estimators = 40,\n",
    "    random_state=17,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "max_depth_values = range(5,15)\n",
    "max_features_values = [4,5,6,7]\n",
    "params = {'max_depth': max_depth_values, 'max_features': max_features_values}\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "\n",
    "gridSearch = GridSearchCV(random_forest, params, cv=skf)\n",
    "gridSearch.fit(X_train_scaled_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf3660b",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b6642",
   "metadata": {},
   "source": [
    "In our dataset, we can observe signs that differ greatly in scaling. Since we've already done the scaling procedure before, we don't need to do it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "acb6d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, train_size=0.7, random_state=17)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train1)\n",
    "X_train_scaled1 = scaler.transform(X_train1)\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train_scaled1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "13a9b29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result: 0.6202846800617733 for {'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# parameter to be searched\n",
    "param_grid = {'n_estimators': range(0,1000,50)}\n",
    "\n",
    "# find the best parameter   \n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "grid_search = GridSearchCV(xgb, param_grid, scoring=\"recall\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X_train_rus, y_train_rus)\n",
    "\n",
    "print(f'Best result: {grid_result.best_score_} for {grid_result.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "458bead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result: 0.6343507676719806 for {'max_depth': 3, 'min_child_weight': 3}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=50)\n",
    "\n",
    "# parameter to be searched\n",
    "param_grid = {'max_depth': [1, 3, 5],\n",
    "             'min_child_weight': [1, 3, 6]}\n",
    "\n",
    "# find the best parameter   \n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "grid_search = GridSearchCV(xgb, param_grid, scoring=\"recall\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X_train_rus, y_train_rus)\n",
    "\n",
    "print(f'Best result: {grid_result.best_score_} for {grid_result.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7fbae2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result: 0.6349837531901217 for {'gamma': 5}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=50, max_depth=3, min_child_weight=3)\n",
    "\n",
    "# parameter to be searched\n",
    "param_grid = {'gamma': [0, 1, 5]}\n",
    "\n",
    "# find the best parameter   \n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "grid_search = GridSearchCV(xgb, param_grid, scoring=\"recall\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X_train_rus, y_train_rus)\n",
    "\n",
    "print(f'Best result: {grid_result.best_score_} for {grid_result.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "894f46f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result: 0.8084344503185354 for {'learning_rate': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=50, max_depth=3, min_child_weight=3, gamma=5)\n",
    "\n",
    "# parameter to be searched\n",
    "param_grid = {'learning_rate': [0.0001, 0.001, 0.01, 0.1]}\n",
    "\n",
    "# find the best parameter   \n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "grid_search = GridSearchCV(xgb, param_grid, scoring=\"recall\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X_train_rus, y_train_rus)\n",
    "\n",
    "print(f'Best result: {grid_result.best_score_} for {grid_result.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2efb28ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.45      0.60     10555\n",
      "           1       0.22      0.82      0.34      1968\n",
      "\n",
      "    accuracy                           0.50     12523\n",
      "   macro avg       0.57      0.63      0.47     12523\n",
      "weighted avg       0.82      0.50      0.56     12523\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(X_test1)\n",
    "y_pred = grid_result.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred, normalize='true'), annot=True, ax=ax)\n",
    "ax.set_title('Confusion Matrix - XGBoost')\n",
    "ax.set_xlabel('Predicted Value')\n",
    "ax.set_ylabel('Real Value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56f685f",
   "metadata": {},
   "source": [
    "**Заметим, что для каждого объекта в выборке возможно 4 ситуации:**\n",
    "\n",
    "1) мы предсказали положительную метку и угадали. Будет относить такие объекты к true positive (TP) группе (true – потому что предсказали мы правильно, а positive – потому что предсказали положительную метку);\n",
    "\n",
    "2) мы предсказали отрицательную метку, но ошиблись – false negative (FN).\n",
    "\n",
    "3) мы предсказали положительную метку, но ошиблись в своём предсказании – false positive (FP) (false, потому что предсказание было неправильным);\n",
    "\n",
    "4) мы предсказали отрицательную метку и угадали – true negative (TN);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "67265a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2160750167448091\n",
      "0.8196138211382114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4736f299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
